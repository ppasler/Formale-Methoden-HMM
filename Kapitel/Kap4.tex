\chapter{Vergleich mit anderen Machine Learning Ansätzen}  \label{mainsec:comp}
Es exisiterne zahllose Ansätze, um maschinelles Lernen abzubilden. Jedes Verfahren hat seinen Ursprung und wurde oft für einen speziellen Anwendungsfall entwickelt. Für jedes Verfahren gibt es zudem wieder verschiedene Erweiterungen, Algorithmen und Implementierungen, die spezielle Probleme lösen. Darum fällt es schwer zu sagen, was der beste Ansatz ist - ohne die genauen Anforderungen zu kennen.

Dennoch werden in den folgenden Abschnitten kurze Gegenüberstellungen, sowie Vor- und Nachteile vorgestellt.


\section{Neuronale Netze} \label{sec:neuron}
Das Neuronale Netz mit allen seinen Ablegern, sind heute wieder eine wichtige Größe im Machine Learning Bereich, nachdem sie Ende der 1960er Jahre wegen einiger Probleme nicht mehr fokusiert wurden. So konnte das Ursprünglich Neuronale Netz kein XOR abbilden konnte und Probleme in der linearen Separierbarkeit hatte. Zudem ist nicht ganz klar, was in einem  neuronalen Netz vorgeht und was die einzelnen Parameter im Detail bedeuten \cite[167]{marsland} - dennoch funktionieren sie. Dies ist im Hidden Markov Model anders, da es sich bei den Parametern, nicht um abstrakte Gewichte, sondern um Wahrscheinlichkeiten handelt.

Rekurrente (tief vorwärtsgerichtete) Neuronale Netze können dank schnellerer CPU oder gar GPU-Nutzung, immer bessere Ergebnisse mit kurzer Rechenzeit liefern. 
Neuronale Netz benötigen sehr viele Daten und Rechenzeit für das Training. Weiterhin können sie nicht mit sequentiellen Daten umgehen, was eine Datenvorverarbeitung nötig macht. Dies gilt ebenso für beiden folgenden Ansätze.

Dennoch bleibt das neuronal Netz eines der beliebsten Machine Learning Ansätzen. Darum exisitert für die Spracherkennung ein hybrider Ansatz, wie ihn \cite{hmmnn} beschreibt, bei dem jeder Zustand einen Eingang in einem Neuronalen Netz bedient.


\section{Support Vector Machine} \label{sec:svm}
Support Vector Machines eigenen sich für die Erkennung von Handschriften, zur klassifizierung von Bildern oder in der Bioinformatik zur klassifizierung von Proteinen.

Probleme ergeben sich, wenn sich die Daten nicht linear Separieren lassen. Hier wendet die SVM den sog. Kernel-Trick an. Dieser überfürht die Daten in einen höher-dimensionalen Raum, sodass sie wieder ``eindeutig'' Trennbar sind (Ausreißer werden vernachlässigt).
Die SVM ist ebenfalls ein populärer und sehr guter Machine Learning Algorithmus, obwohl er, wegen aufwendiger Berechnungen, nicht für große Datenmengen geeignet ist \cite[119]{marsland}. Hier kann das HMM mit seiner besseren Performance punkten. Dennoch hat die SVM stärken in der benötigten Anzahl von Trainingsdaten.

Auch hier existieren Ansätze, die HMMs und SVMs bei der Spracherkennung verbinden. Hierbei wird die zeitliche Variabiliät (sequentielle Daten) mit dem HMM modeliert und die akkustische Komponente mit einer SVM, die hier deutlich robuster funktioniert (Siehe \cite{hmmsvm}).


\section{k-Means} \label{sec:kmeans}
Der k-Means Algorithmus wird häufig in der Bildverarbeitung zur Segementierung eingesetzt. Oftmals wird reicht die euklidische Distanz nicht aus und es müssen weitere Merkmale hinzugezogen werden. Beispielsweise nutzt OpenCV eine Form des k-Means-Algorithmus, um Vordergrund von Hintergrund zu trennen oder Objekte zu erkennen.

Der k-Means-Algorithmus findet aber nicht unbedingt die beste ``globale'' Lösung, sondern findet je nach Wahl der Startpunkte nur lokale Lösungen. Weiterhin wird im Vorfeld der Anzahl der Cluster bestimmt, welche das  Ergebnis stark beeinflussen kann.

Der k-Means Algorithmus ist, wie das Hidden Markov Model, ein Vertreter des unüberwachten Lernens - wohin gegen die beiden vorherigen Ansätze überwachtes Lernen umsetzen. 

Auch für k-Means und das HMM existieren gemeinschaftliche Anwendungen, bspw. werden sie in einem hybriden schreiberunabhängigen Schrifterkennungssystem genutzt, bei dem der k-Means Algorithmus das Clustering im Vorfeld übernimmt und das HMM für die Erkennung zuständig ist \cite{hmmkm}. 
